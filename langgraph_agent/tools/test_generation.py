"""Tools dedicated to the test generation workflow."""
from __future__ import annotations

import json
import re
import traceback
from typing import Any, Dict, List, Optional

from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.tools import tool

from ..config import settings
from ..utils.console import ACCENT_COLOR, INFO_COLOR, RESET, pretty_sub_line, pretty_tool_line

try:  # pragma: no cover - optional dependency resolution
    from test_case_generator.src.models.function_schema import FunctionDefinitionInput
    from test_case_generator.src.tools.signal_traversal_tool import LogicCompletenessGenerator
except Exception as exc:  # pragma: no cover - import guard
    raise RuntimeError(
        "Install with: pip install langchain-anthropic langgraph langchain-core"
    ) from exc


TEST_GENERATOR: Optional[LogicCompletenessGenerator] = None
llm = None


def bind_language_model(model: Any) -> None:
    """Bind the language model instance used for inference tools."""
    global llm
    llm = model


@tool
def initialize_test_gen(json_data: str) -> str:
    """Initialize the test case generator with function definition from JSON."""
    pretty_tool_line("InitTestGen", "Parsing JSON data")

    global TEST_GENERATOR

    try:
        data = json.loads(json_data) if isinstance(json_data, str) else json_data
        function_def = FunctionDefinitionInput.model_validate(data)
        TEST_GENERATOR = LogicCompletenessGenerator(function_def)

        result = (
            f"âœ“ Initialized test generator for function: {function_def.functionName}\n"
            f"  - Power modes: {len(function_def.powerModes or [])}\n"
            f"  - CAN signals: {len(function_def.signalInterface.CAN)}\n"
            f"  - Logic paths: {len(function_def.logicFlow.paths)}"
        )

        pretty_sub_line(result)
        return result

    except Exception as err:  # pragma: no cover - defensive branch
        error_msg = f"Failed to initialize: {err}"
        pretty_sub_line(error_msg)
        traceback.print_exc()
        return error_msg


@tool
def extract_covered_combinations() -> str:
    """Extract already covered test combinations from existing test cases."""
    pretty_tool_line("ExtractCovered", "Analyzing existing test coverage")

    if TEST_GENERATOR is None:
        error = "âš ï¸ Test generator not initialized. Call initialize_test_gen first."
        pretty_sub_line(error)
        return error

    try:
        TEST_GENERATOR._extract_covered_combinations()

        covered_count = len(TEST_GENERATOR.covered_combinations)
        result: Dict[str, Any] = {
            "status": "success",
            "covered_count": covered_count,
            "sample_combinations": [],
        }

        for i, combo in enumerate(TEST_GENERATOR.covered_combinations[:3]):
            try:
                result["sample_combinations"].append(
                    {
                        "index": i + 1,
                        "source": combo.source.pathId,
                        "display": combo.format_display(),
                    }
                )
            except Exception as err:  # pragma: no cover - formatting fallback
                result["sample_combinations"].append(
                    {"index": i + 1, "error": str(err)}
                )

        result_str = json.dumps(result, indent=2, ensure_ascii=False)

        summary = f"âœ“ Extracted {covered_count} covered combinations"
        if covered_count > 0:
            summary += "\n  First few examples:\n"
            for sample in result["sample_combinations"]:
                if "display" in sample:
                    summary += (
                        f"  {sample['index']}. {sample['source']}: {sample['display']}\n"
                    )

        pretty_sub_line(summary)
        return result_str

    except Exception as err:  # pragma: no cover - defensive branch
        error_msg = f"âŒ Error extracting combinations: {err}"
        pretty_sub_line(error_msg)
        traceback.print_exc()
        return json.dumps({"status": "error", "message": error_msg})


@tool
def execute_strategies() -> str:
    """Generate test combinations using strategies (without inferring outputs)."""
    pretty_tool_line("ExecuteStrategies", "Generating test combinations")

    if TEST_GENERATOR is None:
        return json.dumps({"error": "Test generator not initialized"})

    if not TEST_GENERATOR.covered_combinations:
        return json.dumps({"error": "No covered combinations. Call extract_covered_combinations first"})

    try:
        TEST_GENERATOR._execute_strategies()
        total = sum(
            len(combos) for combos in TEST_GENERATOR.generated_combinations.values()
        )

        result = {
            "status": "success",
            "total_generated": total,
            "by_strategy": {
                name: len(combos)
                for name, combos in TEST_GENERATOR.generated_combinations.items()
            },
            "note": "Outputs are empty. Call infer_outputs_with_ai to infer expected results.",
        }

        summary = f"âœ“ Generated {total} combinations (outputs empty)\n"
        for name, count in result["by_strategy"].items():
            summary += f"  - {name}: {count}\n"

        pretty_sub_line(summary)
        return json.dumps(result, ensure_ascii=False)

    except Exception as err:  # pragma: no cover - defensive branch
        pretty_sub_line(f"Error: {err}")
        traceback.print_exc()
        return json.dumps({"error": str(err)})


@tool
def infer_outputs_with_ai() -> str:
    """Infer expected outputs for generated combinations using the bound language model."""
    pretty_tool_line("InferOutputs", "AIè¯­ä¹‰æ¨ç†ä¸­")

    if not TEST_GENERATOR or not TEST_GENERATOR.generated_combinations:
        return json.dumps([])

    if llm is None:  # pragma: no cover - configuration guard
        raise RuntimeError("Language model has not been bound. Call bind_language_model first.")

    func = TEST_GENERATOR.function_def

    signals_def: Dict[str, Dict[str, str]] = {}
    if func.powerModes:
        signals_def["powerMode"] = {pm: f"ç”µæº{pm}çŠ¶æ€" for pm in func.powerModes}

    for sig in func.signalInterface.CAN:
        signals_def[sig.signalName] = {v.value: v.description for v in sig.definedValues}

    for sig in func.signalInterface.HARDWIRE:
        signals_def[sig.signalName] = {v.value: v.description for v in sig.definedValues}

    paths_info: List[Dict[str, Any]] = []
    for path in func.logicFlow.paths:
        path_data = {
            "pathId": path.pathId,
            "description": path.pathDescription,
            "conditions": {
                "preconditions": [],
                "trigger": {"logic": path.conditions.trigger.logic, "signals": []},
            },
            "outputs_template": path.outputs.model_dump(),
        }

        for pc in path.conditions.preconditions:
            if pc.type == "powerMode":
                values = pc.value if isinstance(pc.value, list) else [pc.value]
                path_data["conditions"]["preconditions"].append(
                    {
                        "signal": "powerMode",
                        "required_values": [
                            f"{v}({signals_def['powerMode'].get(v, v)})" for v in values
                        ],
                    }
                )
            else:
                values = pc.value if isinstance(pc.value, list) else [pc.value]
                sig_defs = signals_def.get(pc.signalName, {})
                path_data["conditions"]["preconditions"].append(
                    {
                        "signal": pc.signalName,
                        "required_values": [
                            f"{v}({sig_defs.get(v, 'æœªçŸ¥')})" for v in values
                        ],
                    }
                )

        for sig in path.conditions.trigger.signals:
            values = sig.value if isinstance(sig.value, list) else [sig.value]
            sig_defs = signals_def.get(sig.signalName, {})
            path_data["conditions"]["trigger"]["signals"].append(
                {
                    "signal": sig.signalName,
                    "required_values": [
                        f"{v}({sig_defs.get(v, 'æœªçŸ¥')})" for v in values
                    ],
                }
            )

        paths_info.append(path_data)

    if not paths_info:
        return json.dumps([])

    combos_list: List[Dict[str, Any]] = []
    for strategy, combos in TEST_GENERATOR.generated_combinations.items():
        for idx, combo in enumerate(combos):
            cid = f"{strategy}_{idx + 1}"

            pre: Dict[str, str] = {}
            if combo.preconditions.power_mode:
                pm = combo.preconditions.power_mode
                pre["powerMode"] = f"{pm}({signals_def.get('powerMode', {}).get(pm, 'æœªçŸ¥')})"
            if combo.preconditions.can_signal:
                sig_name = combo.preconditions.can_signal.signalName
                sig_val = combo.preconditions.can_signal.value
                desc = signals_def.get(sig_name, {}).get(sig_val, "æœªçŸ¥")
                pre[sig_name] = f"{sig_val}({desc})"

            trg: Dict[str, str] = {}
            for sig in combo.trigger.can_signals:
                desc = signals_def.get(sig.signalName, {}).get(sig.value, "æœªçŸ¥")
                trg[sig.signalName] = f"{sig.value}({desc})"

            combos_list.append({"id": cid, "preconditions": pre, "trigger": trg})

    prompt = f"""# ä»»åŠ¡ï¼šåŸºäºè¯­ä¹‰æ¨ç†æµ‹è¯•ç»„åˆçš„é¢„æœŸè¾“å‡º

## å®Œæ•´ä¿¡å·å®šä¹‰
{json.dumps(signals_def, indent=2, ensure_ascii=False)}

## å·²çŸ¥é€»è¾‘è·¯å¾„ï¼ˆå…±{len(paths_info)}ä¸ªï¼‰

"""

    for path in paths_info:
        prompt += f"""
### è·¯å¾„: {path['pathId']}
**åŠŸèƒ½æè¿°**: {path['description']}

**å‰ç½®æ¡ä»¶è¦æ±‚**:
"""
        for cond in path["conditions"]["preconditions"]:
            prompt += f"- {cond['signal']} å¿…é¡»æ˜¯: {', '.join(cond['required_values'])}\n"

        prompt += f"\n**è§¦å‘æ¡ä»¶è¦æ±‚ ({path['conditions']['trigger']['logic']})**:\n"
        for sig in path["conditions"]["trigger"]["signals"]:
            prompt += f"- {sig['signal']} å¿…é¡»æ˜¯: {', '.join(sig['required_values'])}\n"

        prompt += (
            "\n**è·¯å¾„è¾“å‡ºæ¨¡æ¿**ï¼ˆâ­è¿™æ˜¯æ¨ç†çš„å”¯ä¸€æ¨¡æ¿â­ï¼‰:\n"
            f"```json\n{json.dumps(path['outputs_template'], indent=2, ensure_ascii=False)}\n```\n"
            "---\n"
        )

    prompt += f"""
    ## æ¨ç†è§„åˆ™ï¼ˆâ­æ ¸å¿ƒé€»è¾‘â­ï¼‰

    ### ç¬¬ä¸€æ­¥ï¼šè¯­ä¹‰åŒ¹é…åˆ¤æ–­

    å¯¹äºæ¯ä¸ªç»„åˆï¼Œæ£€æŸ¥å…¶ä¿¡å·å€¼çš„**æè¿°**æ˜¯å¦ä¸è·¯å¾„è¦æ±‚çš„**æè¿°è¯­ä¹‰ç›¸åŒæˆ–ç›¸è¿‘**ï¼š

    **ç¤ºä¾‹1ï¼šè¯­ä¹‰åŒç±»**
    - è·¯å¾„è¦æ±‚: EspAbsFailrå¿…é¡»æ˜¯ "0x1(æ•…éšœ)" æˆ– "0x2(ä¸¥é‡æ•…éšœ)"
    - ç»„åˆå€¼: EspAbsFailr = "0x3(è¶…çº§æ•…éšœ)"
    - åˆ†æ: "è¶…çº§æ•…éšœ"å’Œ"æ•…éšœ"ã€"ä¸¥é‡æ•…éšœ"éƒ½å«"æ•…éšœ"å…³é”®è¯ï¼Œå±äºåŒä¸€ç±»
    - ç»“è®º: âœ… è¯­ä¹‰åŒ¹é…

    **ç¤ºä¾‹2ï¼šè¯­ä¹‰ä¸åŒç±»**
    - è·¯å¾„è¦æ±‚: EspAbsFailrå¿…é¡»æ˜¯ "0x1(æ•…éšœ)" æˆ– "0x2(ä¸¥é‡æ•…éšœ)"
    - ç»„åˆå€¼: EspAbsFailr = "0x0(æ— æ•…éšœ)"
    - åˆ†æ: "æ— æ•…éšœ"è¡¨ç¤ºæ­£å¸¸ï¼Œå’Œ"æ•…éšœç±»"ç›¸å
    - ç»“è®º: âŒ è¯­ä¹‰ä¸åŒ¹é…

    **ç¤ºä¾‹3ï¼šè¯­ä¹‰ä¸åŒç±»**
    - è·¯å¾„è¦æ±‚: EspAbsFailrå¿…é¡»æ˜¯ "0x1(æ•…éšœ)" æˆ– "0x2(ä¸¥é‡æ•…éšœ)"
    - ç»„åˆå€¼: EspAbsFailr = "0x4(æ— )"
    - åˆ†æ: "æ— "è¡¨ç¤ºæ²¡æœ‰æ•…éšœï¼Œå’Œ"æ•…éšœç±»"ä¸åŒ
    - ç»“è®º: âŒ è¯­ä¹‰ä¸åŒ¹é…

    **ç¤ºä¾‹4ï¼šç”µæºçŠ¶æ€**
    - è·¯å¾„è¦æ±‚: powerModeå¿…é¡»æ˜¯ "ON" æˆ– "ACC"
    - ç»„åˆå€¼: powerMode = "OFF"
    - åˆ†æ: "OFF"ä¸åœ¨è¦æ±‚åˆ—è¡¨ä¸­ï¼Œè¯­ä¹‰ä¸åŒ¹é…
    - ç»“è®º: âŒ è¯­ä¹‰ä¸åŒ¹é…

    ### ç¬¬äºŒæ­¥ï¼šæ¨æ–­è¾“å‡º

    #### æƒ…å†µAï¼šæ‰€æœ‰æ¡ä»¶éƒ½è¯­ä¹‰åŒ¹é…
    â†’ **åŸæ ·ä½¿ç”¨è·¯å¾„çš„outputsæ¨¡æ¿**

    #### æƒ…å†µBï¼šä»»ä¸€æ¡ä»¶è¯­ä¹‰ä¸åŒ¹é…
    â†’ **åŸºäºè·¯å¾„outputsæ¨¡æ¿æ¨æ–­ç›¸åçŠ¶æ€**ï¼š

       **indicators** - ä¿®æ”¹actionå­—æ®µï¼š
       - "ç‚¹äº®" â†’ "ç†„ç­"
       - "é—ªçƒ" â†’ "ç†„ç­"
       - "å¸¸äº®" â†’ "ç†„ç­"

       **texts** - å±•ç¤º/ä¸å±•ç¤ºï¼ˆâ­å†…å®¹ä¸å˜â­ï¼‰ï¼š
       - åŒ¹é…æ—¶ï¼šä¿ç•™æ•°ç»„å†…å®¹ï¼ˆå±•ç¤ºæ–‡æœ¬ï¼‰
       - ä¸åŒ¹é…æ—¶ï¼šæ¸…ç©ºæ•°ç»„ [] ï¼ˆä¸å±•ç¤ºæ–‡æœ¬ï¼‰

       **sounds** - æ’­æ”¾/ä¸æ’­æ”¾ï¼š
       - åŒ¹é…æ—¶ï¼šä¿ç•™æ•°ç»„å†…å®¹ï¼ˆæ’­æ”¾å£°éŸ³ï¼‰
       - ä¸åŒ¹é…æ—¶ï¼šæ¸…ç©ºæ•°ç»„ [] ï¼ˆä¸æ’­æ”¾å£°éŸ³ï¼‰

       **images** - æ˜¾ç¤º/ä¸æ˜¾ç¤ºï¼š
       - åŒ¹é…æ—¶ï¼šä¿ç•™æ•°ç»„å†…å®¹ï¼ˆæ˜¾ç¤ºå›¾ç‰‡ï¼‰
       - ä¸åŒ¹é…æ—¶ï¼šæ¸…ç©ºæ•°ç»„ [] ï¼ˆä¸æ˜¾ç¤ºå›¾ç‰‡ï¼‰

    **æ¨æ–­ç¤ºä¾‹1**ï¼š

    è·¯å¾„outputsæ¨¡æ¿:
    ```json
    {{
      "indicators": [{{"name": "ABSæ•…éšœæŒ‡ç¤ºç¯", "action": "ç‚¹äº®"}}],
      "texts": [],
      "sounds": [],
      "images": []
    }}
    ```

    âœ… åŒ¹é…æ—¶ â†’ åŸæ ·:
    ```json
    {{
      "indicators": [{{"name": "ABSæ•…éšœæŒ‡ç¤ºç¯", "action": "ç‚¹äº®"}}],
      "texts": [],
      "sounds": [],
      "images": []
    }}
    ```

    âŒ ä¸åŒ¹é…æ—¶ â†’ æ¨æ–­ç›¸å:
    ```json
    {{
      "indicators": [{{"name": "ABSæ•…éšœæŒ‡ç¤ºç¯", "action": "ç†„ç­"}}],
      "texts": [],
      "sounds": [],
      "images": []
    }}
    ```

## å¾…æ¨ç†ç»„åˆï¼ˆå…±{len(combos_list)}ä¸ªï¼‰

"""

    for combo in combos_list[:40]:
        prompt += (
            f"{combo['id']}: å‰ç½®{combo['preconditions']}, è§¦å‘{combo['trigger']}\n"
        )

    prompt += """
## è¾“å‡ºæ ¼å¼

è¿”å›JSONæ•°ç»„ï¼Œæ ¼å¼ï¼š
```json
[
  {
    "combination_id": "ç»„åˆID",
    "matched": true/false,
    "reasoning": "ç®€çŸ­è¯´æ˜ï¼šå“ªäº›æ¡ä»¶åŒ¹é…/ä¸åŒ¹é…ï¼Œä¸ºä»€ä¹ˆ",
    "outputs": {ä¸¥æ ¼æŒ‰ç…§è·¯å¾„æ¨¡æ¿çš„ç»“æ„}
  }
]
```

**é‡è¦æé†’**ï¼š
1. outputså¿…é¡»ä¸¥æ ¼éµå¾ªè·¯å¾„outputsæ¨¡æ¿çš„ç»“æ„
2. ä¸èƒ½æ·»åŠ è·¯å¾„æ¨¡æ¿ä¸­æ²¡æœ‰çš„å­—æ®µ
3. è·¯å¾„æ¨¡æ¿ä¸­ä¸ºç©ºçš„å­—æ®µå¿…é¡»ä¿æŒç©º
4. åªåœ¨è·¯å¾„æ¨¡æ¿æœ‰å†…å®¹çš„å­—æ®µä¸­æ¨æ–­ç›¸åçŠ¶æ€

è¯·å¼€å§‹æ¨ç†æ‰€æœ‰{len(combos_list)}ä¸ªç»„åˆã€‚
"""

    print(f"{INFO_COLOR}  ğŸ¤– LLMè¯­ä¹‰æ¨ç†{len(combos_list)}ä¸ªç»„åˆ...{RESET}")
    response = llm.invoke(
        [
            SystemMessage(
                content="ä½ æ˜¯æµ‹è¯•æ¨ç†ä¸“å®¶ã€‚åŸºäºä¿¡å·æè¿°çš„è¯­ä¹‰è¿›è¡Œæ¨ç†ï¼Œä¸¥æ ¼éµå¾ªè¾“å‡ºæ¨¡æ¿ã€‚"
            ),
            HumanMessage(content=prompt),
        ]
    )

    content = response.content if isinstance(response.content, str) else str(response.content)

    results: List[Dict[str, Any]] = []
    try:
        match = re.search(r"```(?:json)?\s*(.*?)\s*```", content, re.DOTALL)
        if match:
            parsed = json.loads(match.group(1))
        else:
            match = re.search(r"\[.*\]", content, re.DOTALL)
            if match:
                parsed = json.loads(match.group(0))
            else:
                parsed = json.loads(content)

        if isinstance(parsed, list):
            results = parsed
            print(f"{INFO_COLOR}  âœ“ æˆåŠŸè§£æ{len(results)}ä¸ªæ¨ç†ç»“æœ{RESET}")
    except Exception as err:
        print(f"{ACCENT_COLOR}  âš ï¸ JSONè§£æå¤±è´¥: {err}{RESET}")

    existing_ids = {r.get("combination_id") for r in results}
    default_outputs = {"indicators": [], "texts": [], "sounds": [], "images": []}

    for combo in combos_list:
        if combo["id"] not in existing_ids:
            template = paths_info[0]["outputs_template"] if paths_info else default_outputs
            results.append(
                {
                    "combination_id": combo["id"],
                    "matched": False,
                    "reasoning": "LLMæœªæ¨ç†ï¼Œä½¿ç”¨é»˜è®¤",
                    "outputs": template,
                }
            )

    final_results: List[Dict[str, Any]] = []
    for r in results:
        final_results.append(
            {
                "combination_id": r["combination_id"],
                "reasoning": r.get("reasoning", "æ— æ¨ç†è¯´æ˜"),
                "outputs": r.get("outputs", default_outputs),
            }
        )

    pretty_sub_line(f"âœ“ æ¨ç†å®Œæˆ: {len(final_results)}ä¸ª")

    print(f"\n{INFO_COLOR}æ¨ç†ç¤ºä¾‹:{RESET}")
    for r in final_results[:3]:
        summary_parts = []
        for key, val in r["outputs"].items():
            if val and len(val) > 0:
                summary_parts.append(f"{key}Ã—{len(val)}")
        summary = ", ".join(summary_parts) if summary_parts else "ç©º"
        print(f"  {r['combination_id']}: {summary}")
        print(f"    æ¨ç†: {r['reasoning'][:200]}...")

    return json.dumps(final_results, ensure_ascii=False)


@tool
def apply_inferred_outputs(inferred_results: str) -> str:
    """Apply AI inferred outputs back onto generated combinations."""
    pretty_tool_line("ApplyOutputs", "åº”ç”¨æ¨ç†ç»“æœ")

    if not TEST_GENERATOR:
        return json.dumps({"error": "æœªåˆå§‹åŒ–"})

    try:
        results = json.loads(inferred_results) if isinstance(inferred_results, str) else inferred_results
        applied = 0

        for item in results:
            cid = item.get("combination_id", "")
            outputs = item.get("outputs", {})

            if not cid:
                continue

            parts = cid.rsplit("_", 1)
            if len(parts) != 2:
                continue

            strategy_name, idx_str = parts

            if strategy_name not in TEST_GENERATOR.generated_combinations:
                continue

            try:
                idx = int(idx_str) - 1
                combos = TEST_GENERATOR.generated_combinations[strategy_name]

                if 0 <= idx < len(combos):
                    combos[idx].outputs = {
                        "indicators": outputs.get("indicators", []),
                        "texts": outputs.get("texts", []),
                        "sounds": outputs.get("sounds", []),
                        "images": outputs.get("images", []),
                    }
                    applied += 1

                    if applied <= 3:
                        action = (
                            combos[idx].outputs["indicators"][0]["action"]
                            if combos[idx].outputs["indicators"]
                            else "æ— "
                        )
                        print(f"{INFO_COLOR}  [Debug] {cid} -> {action}{RESET}")

            except Exception as err:  # pragma: no cover - defensive branch
                print(f"{ACCENT_COLOR}  [Error] {cid}: {err}{RESET}")
                continue

        pretty_sub_line(f"âœ… åº”ç”¨: {applied}/{len(results)}")

        sample_combo = None
        for strategy_name, combos in TEST_GENERATOR.generated_combinations.items():
            if combos:
                sample_combo = combos[0]
                break

        if sample_combo and sample_combo.outputs:
            print(f"{INFO_COLOR}  [éªŒè¯] ç¤ºä¾‹outputs: {sample_combo.outputs}{RESET}")
        else:
            print(f"{ACCENT_COLOR}  [è­¦å‘Š] ç¤ºä¾‹ç»„åˆçš„outputsä»ä¸ºç©ºï¼{RESET}")

        return json.dumps({"status": "success", "applied": applied, "total": len(results)})

    except Exception as err:  # pragma: no cover - defensive branch
        error_msg = f"Error: {err}"
        pretty_sub_line(error_msg)
        traceback.print_exc()
        return json.dumps({"error": error_msg})


@tool
def get_test_results() -> str:
    """Collect generation statistics and persist them to disk."""
    pretty_tool_line("GetResults", "Collecting test results")

    if TEST_GENERATOR is None:
        error = "âš ï¸ Test generator not initialized."
        pretty_sub_line(error)
        return error

    try:
        result = {
            "function_name": TEST_GENERATOR.function_def.functionName,
            "covered_combinations": len(TEST_GENERATOR.covered_combinations),
            "generated_combinations": {},
            "total_generated": 0,
        }

        total = 0
        for strategy_name, combos in TEST_GENERATOR.generated_combinations.items():
            count = len(combos)
            total += count
            result["generated_combinations"][strategy_name] = count

        result["total_generated"] = total

        output_file = settings.workspace / "test_generation_results.json"
        with output_file.open("w", encoding="utf-8") as f:
            json.dump(result, f, indent=2, ensure_ascii=False)

        summary = (
            "âœ“ Test generation completed!\n"
            f"  Function: {result['function_name']}\n"
            f"  Covered: {result['covered_combinations']} combinations\n"
            f"  Generated: {result['total_generated']} new combinations\n"
            f"  Results saved to: {output_file.relative_to(settings.workspace)}"
        )

        pretty_sub_line(summary)
        return json.dumps(result, indent=2, ensure_ascii=False)

    except Exception as err:  # pragma: no cover - defensive branch
        error_msg = f"âŒ Error getting results: {err}"
        pretty_sub_line(error_msg)
        traceback.print_exc()
        return json.dumps({"status": "error", "message": error_msg})


@tool
def export_test_cases(output_format: str = "json") -> str:
    """Export generated test cases in the requested format."""
    pretty_tool_line("ExportCases", f"å¯¼å‡º{output_format}æ ¼å¼")

    if not TEST_GENERATOR:
        return json.dumps({"error": "æœªåˆå§‹åŒ–"})

    try:
        all_cases = []
        case_id = 1

        for strategy_name, combos in TEST_GENERATOR.generated_combinations.items():
            for combo in combos:
                preconditions: Dict[str, Any] = {}
                if combo.preconditions.power_mode:
                    preconditions["powerMode"] = combo.preconditions.power_mode
                if combo.preconditions.can_signal:
                    preconditions[
                        combo.preconditions.can_signal.signalName
                    ] = combo.preconditions.can_signal.value

                trigger_signals: Dict[str, Any] = {}
                for sig in combo.trigger.can_signals:
                    trigger_signals[sig.signalName] = sig.value

                outputs = (
                    combo.outputs
                    if combo.outputs
                    else {"indicators": [], "texts": [], "sounds": [], "images": []}
                )

                test_case = {
                    "id": f"TC_{case_id:03d}",
                    "strategy": strategy_name,
                    "preconditions": preconditions,
                    "trigger": {
                        "logic": combo.trigger.logic,
                        "signals": trigger_signals,
                    },
                    "expected_outputs": outputs,
                    "source": combo.source.pathId,
                }

                all_cases.append(test_case)
                case_id += 1

        with_outputs = sum(
            1 for c in all_cases if any(c["expected_outputs"].values())
        )

        if output_format == "json":
            output_file = settings.workspace / "generated_test_cases.json"
            with output_file.open("w", encoding="utf-8") as f:
                json.dump(
                    {
                        "function": TEST_GENERATOR.function_def.functionName,
                        "total_cases": len(all_cases),
                        "with_outputs": with_outputs,
                        "without_outputs": len(all_cases) - with_outputs,
                        "test_cases": all_cases,
                    },
                    f,
                    indent=2,
                    ensure_ascii=False,
                )
        else:
            output_file = settings.workspace / "generated_test_cases.md"
            lines = [
                f"# {TEST_GENERATOR.function_def.functionName} æµ‹è¯•ç”¨ä¾‹\n",
                f"**æ€»è®¡**: {len(all_cases)} ä¸ªç”¨ä¾‹\n",
                f"**æœ‰é¢„æœŸ**: {with_outputs} ä¸ª\n",
            ]

            for case in all_cases:
                lines.append(f"\n## {case['id']} - {case['strategy']}\n")
                lines.append(f"**å‰ç½®**: {case['preconditions']}\n")
                lines.append(
                    f"**è§¦å‘**: {case['trigger']['signals']}\n"
                )
                lines.append("**é¢„æœŸ**:")
                if case["expected_outputs"]["indicators"]:
                    for ind in case["expected_outputs"]["indicators"]:
                        lines.append(
                            f"  - {ind['name']}: {ind['action']}"
                        )
                else:
                    lines.append("  - æ— ")
                lines.append("")

            output_file.write_text("\n".join(lines), encoding="utf-8")

        summary = (
            f"âœ“ å¯¼å‡º {len(all_cases)} ä¸ªç”¨ä¾‹\n"
            f"  - æœ‰é¢„æœŸ: {with_outputs}\n"
            f"  - æ— é¢„æœŸ: {len(all_cases) - with_outputs}"
        )

        if len(all_cases) - with_outputs > 0:
            summary += (
                f"\n  âš ï¸ è­¦å‘Š: {len(all_cases) - with_outputs} ä¸ªç”¨ä¾‹æ²¡æœ‰é¢„æœŸï¼"
            )

        pretty_sub_line(summary)
        return str(output_file)

    except Exception as err:  # pragma: no cover - defensive branch
        error_msg = f"Error: {err}"
        pretty_sub_line(error_msg)
        traceback.print_exc()
        return error_msg


__all__ = [
    "apply_inferred_outputs",
    "bind_language_model",
    "execute_strategies",
    "export_test_cases",
    "extract_covered_combinations",
    "get_test_results",
    "infer_outputs_with_ai",
    "initialize_test_gen",
]
